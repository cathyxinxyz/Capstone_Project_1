{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the collection of codes that read food atlas datasets and CDC health indicator datasets from Github repository, integrate datasets and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#merge food atlas datasets into one\n",
    "import pandas as pd\n",
    "\n",
    "dfs=list()\n",
    "url_folder='https://raw.githubusercontent.com/cathyxinxyz/Capstone_Project_1/master/Datasets/Food_atlas/'\n",
    "filenames=['ACCESS','ASSISTANCE','HEALTH','INSECURITY','LOCAL','PRICES_TAXES','RESTAURANTS','SOCIOECONOMIC','STORES']\n",
    "for i,filename in enumerate(filenames):\n",
    "    url=url_folder+filename+\".csv\"   \n",
    "    d=pd.read_csv(url,index_col='FIPS',encoding=\"ISO-8859-1\")\n",
    "    #append datasets to the list and drop the redundent columns:'State' and 'County'\n",
    "    if i!=0:\n",
    "        dfs.append(d.drop(['State', 'County'], axis=1))\n",
    "    else:\n",
    "        dfs.append(d)\n",
    "\n",
    "#merge datasets\n",
    "df_merge=pd.concat(dfs, join='outer', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (df_merge.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check columns for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merge.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_null_values_percol=df_merge.isnull().sum(axis=0)\n",
    "#columns with over 100 missing values\n",
    "cols_with_over_50_null_values=number_null_values_percol[number_null_values_percol>100]\n",
    "print (cols_with_over_50_null_values.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#drop these columns first\n",
    "df_merge=df_merge.drop(list(cols_with_over_50_null_values.index), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check number of remaining columns\n",
    "print (df_merge.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categorizes columns into three groups: category data ('State' and 'County'), count data, percent data, # per 1000 pop, and percent change\n",
    "\n",
    "columns to keep: category data ('State' and 'County'), percent data, # per 1000 pop, and percent change; remove count data because it is not adjusted by population size\n",
    "\n",
    "Each column name is highly abstract and unreadable, need to extract info from the variable information provided by Food_atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "url='https://raw.githubusercontent.com/cathyxinxyz/Capstone_Project_1/master/Datasets/Food_atlas/variable_info.csv'\n",
    "var_info_df=pd.read_csv(url,encoding=\"ISO-8859-1\")\n",
    "var_info_dict=defaultdict(list)\n",
    "for idx in var_info_df.index:\n",
    "    k=var_info_df['Units'][idx]\n",
    "    var_info_dict[k].append(var_info_df['Variable Code'][idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "further filter varaibles based on following principles:\n",
    "i. keep variables that are adjusted by population size: '% change', 'Percent', '# per 1,000 pop','Percentage points';\n",
    "ii. keep variables that are mostly valuable for analysis\n",
    "iii. keep variables where values are valid: e.g. no negative values for variables with units as 'Percent' or '# per 1,000 pop'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#units to keep: '% change', 'Percent', '# per 1,000 pop','Percentage points'\n",
    "for k in var_info_dict.keys():\n",
    "    if k not in ['% change', 'Percent', '# per 1,000 pop','Percentage points'] and var_info_dict[k] not in ['State','County']:\n",
    "        df_merge = df_merge[df_merge.columns.difference(var_info_dict[k])]\n",
    "        \n",
    "#print (df_merge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#view variables\n",
    "for idx in var_info_df.index:\n",
    "    k=var_info_df['Units'][idx]\n",
    "    k1=var_info_df['Category Code'][idx]\n",
    "    k2=var_info_df['Sub_subcategory Name'][idx]\n",
    "    var=var_info_df['Variable Code'][idx]\n",
    "    \n",
    "    if var in df_merge.columns:\n",
    "        print (k1,k2,k,var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df_merge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Restaurant Availability and Expenditures,RESTAURANTS,Expenditures per capita,fast food,2007*,PC_FFRSALES07,CNTY10,Dollars\n",
    "Restaurant Availability and Expenditures,RESTAURANTS,Expenditures per capita,fast food,2012*,PC_FFRSALES12,CNTY10,Dollars\n",
    "Restaurant Availability and Expenditures,RESTAURANTS,Expenditures per capita,restaurants,2007*,PC_FSRSALES07,CNTY10,Dollars\n",
    "Restaurant Availability and Expenditures,RESTAURANTS,Expenditures per capita,restaurants,2012*,PC_FSRSALES12,CNTY10,Dollars'''\n",
    "df_merge=df_merge[['PCH_LACCESS_POP_10_15','PCT_LACCESS_POP10','PCT_LACCESS_POP15',\n",
    "                   'PCH_LACCESS_LOWI_10_15','PCT_LACCESS_LOWI10', 'PCT_LACCESS_LOWI15', \n",
    "                   'PCT_LACCESS_CHILD10','PCT_LACCESS_CHILD15',\n",
    "                   'PCH_LACCESS_SENIORS_10_15','PCT_LACCESS_SENIORS10','PCT_LACCESS_SENIORS15',\n",
    "                   'PCH_GROC_09_14','GROCPTH09','GROCPTH14',\n",
    "                   'SUPERCPTH09','SUPERCPTH14','PCH_CONVS_09_14', \n",
    "                   'CONVSPTH09','CONVSPTH14','PCH_CONVSPTH_09_14', \n",
    "                   'SPECSPTH09','SPECSPTH14',\n",
    "                   'PCH_SNAPS_12_16','SNAPSPTH12','SNAPSPTH16','PCH_SNAPSPTH_12_16',\n",
    "                   'PCH_WICS_08_12','WICSPTH08','WICSPTH12','PCH_WICSPTH_08_12',\n",
    "                   'PCH_FFR_09_14','FFRPTH09','FFRPTH14',\n",
    "                    'PCH_FFRPTH_09_14','PCH_FSR_09_14','FSRPTH09',\n",
    "                    'FSRPTH14','PCT_CACFP09','PCT_CACFP15','PCH_CACFP_09_15',\n",
    "                    'FOODINSEC_10_12','FOODINSEC_13_15','CH_FOODINSEC_12_15',\n",
    "                    'VLFOODSEC_10_12','VLFOODSEC_13_15','CH_VLFOODSEC_12_15',\n",
    "                    'RECFACPTH09','RECFACPTH14',\n",
    "                    'PCT_NHWHITE10', 'PCT_NHBLACK10', 'PCT_HISP10','PCT_NHASIAN10',\n",
    "                    'PCT_NHNA10','PCT_NHPI10','PCT_65OLDER10','PCT_18YOUNGER10','POVRATE15',\n",
    "                     'PCT_DIABETES_ADULTS08', 'PCT_DIABETES_ADULTS13','PCT_OBESE_ADULTS08','PCT_OBESE_ADULTS13',\n",
    "                    'State','County']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_merge.shape)\n",
    "#view variables\n",
    "for idx in var_info_df.index:\n",
    "    k=var_info_df['Units'][idx]\n",
    "    k1=var_info_df['Category Code'][idx]\n",
    "    k2=var_info_df['Sub_subcategory Name'][idx]\n",
    "    var=var_info_df['Variable Code'][idx]\n",
    "    \n",
    "    if var in df_merge.columns:\n",
    "        print (k1,k2,k,var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#devide dataframe into two: one with variables measured at one year and one with variables as percent change„ÄÅ\n",
    "var_timepoint=list()\n",
    "var_percentchange=list()\n",
    "for idx in var_info_df.index:\n",
    "    k=var_info_df['Units'][idx]\n",
    "    k1=var_info_df['Category Code'][idx]\n",
    "    k2=var_info_df['Sub_subcategory Name'][idx]\n",
    "    var=var_info_df['Variable Code'][idx]\n",
    "    \n",
    "    if var in df_merge.columns: \n",
    "        if k in ['Percent', '# per 1,000 pop']:\n",
    "            var_timepoint.append(var)\n",
    "        elif k in ['% change','Percentage points']:\n",
    "            var_percentchange.append(var)\n",
    "var_timepoint.extend(['State','County'])\n",
    "var_percentchange.extend(['State','County'])\n",
    "df_tp=df_merge[var_timepoint]\n",
    "df_pr=df_merge[var_percentchange]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (df_tp.shape)\n",
    "print (df_pr.shape)\n",
    "print (df_pr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check weather each column has valid values:\n",
    "####### columns with units 'Percent' should have values between 0 and 100, any value that fall out of this range should be changed to NaN values\n",
    "###### \n",
    "######\n",
    "######\n",
    "\n",
    "#Replace invalid values with np.nan\n",
    "import numpy as np\n",
    "\n",
    "for idx in var_info_df.index:\n",
    "    k=var_info_df['Units'][idx]\n",
    "    k1=var_info_df['Category Code'][idx]\n",
    "    k2=var_info_df['Sub_subcategory Name'][idx]\n",
    "    var=var_info_df['Variable Code'][idx]\n",
    "    \n",
    "    if k =='Percent' and var in df_tp.columns: \n",
    "        ser=df_tp[var]<0 \n",
    "        ser=ser+df_tp[var]>100\n",
    "        if ser.sum()>0:\n",
    "            print ((k1,k2,var,ser.sum()))\n",
    "            df_tp[var][(df_tp[var]<0)|(df_tp[var]>100)]=np.nan\n",
    "    elif k=='# per 1,000 pop' and var in df_tp.columns:\n",
    "        ser=df_tp[var]<0\n",
    "        ser=ser+df_tp[var]>1000\n",
    "        if ser.sum()>0:\n",
    "            print ((k1,k2,var,ser.sum()))\n",
    "            df_tp[var][(df_tp[var]<0)|(df_tp[var]>1000)]=np.nan\n",
    "    elif k=='Percentage points' and var in df_pr.columns:\n",
    "        ser=df_pr[var]>100\n",
    "        ser=df_pr[var]<-100\n",
    "        if ser.sum()>0:\n",
    "            print ((k1,k2,var,ser.sum())) \n",
    "            df_pr[var][(df_pr[var]<-100)|(df_pr[var]>100)]=np.nan\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#break df_tp into two sets: variables measured at the earlier time point: df_tp_1; and variables measured at the earlier time point: df_tp_2\n",
    "\n",
    "#group the same measure into tuples, the same measure share the same name except the last two digits which indicate the year of the measure\n",
    "var_grouped_by_measures=defaultdict(list)\n",
    "early_measure_list=['State','County']\n",
    "late_measure_list=['State','County']\n",
    "for idx in var_info_df.index:\n",
    "    k=var_info_df['Units'][idx]\n",
    "    k1=var_info_df['Category Code'][idx]\n",
    "    k2=var_info_df['Sub_subcategory Name'][idx]\n",
    "    var=var_info_df['Variable Code'][idx]\n",
    "    \n",
    "    if var in df_tp.columns and var not in ['State','County']:\n",
    "        var_grouped_by_measures[(k1,k2)].append((var, float(var[-2:])))\n",
    "    \n",
    "for v in var_grouped_by_measures.values():\n",
    "    v.sort(key=lambda tup: tup[-1])\n",
    "    early_measure_list.append(v[0][0])  \n",
    "    late_measure_list.append(v[-1][0])\n",
    "\n",
    "df_tp_1=df_tp[early_measure_list]\n",
    "df_tp_2=df_tp[late_measure_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (df_tp_1.shape)\n",
    "print (df_tp_2.shape)\n",
    "print (df_pr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df_tp_1.columns)\n",
    "print (df_tp_2.columns)\n",
    "print (df_pr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_trans_dict={'PCT_LACCESS_POP':'Low_Access_Overall',\n",
    "               'PCT_LACCESS_LOWI':'Low_Access_Low_income',\n",
    "               'PCT_LACCESS_CHILD':'Low_Access_Children',\n",
    "               'PCT_LACCESS_SENIORS':'Low_Access_Senior',\n",
    "               'GROCPTH':'Grocery',\n",
    "                'SUPERCPTH':'Supercenter',\n",
    "                'CONVSPTH':'Convenience',\n",
    "                'SPECSPTH':'Specialized',\n",
    "                'SNAPSPTH':'SNAP_store',\n",
    "                'WICSPTH':'WIC_store',\n",
    "                 'FFRPTH':'Fast_food',\n",
    "                 'FSRPTH':'Full_service',\n",
    "                 'PC_FFRSALES':'Expend_fast_food',\n",
    "                 'PC_FSRSALES':'Expend_full_service',\n",
    "                 'PCT_CACFP':'Assistance',\n",
    "                 'FOODINSEC':'Low_insecurity',\n",
    "                 'VLFOODSEC':'Very_low_insecurity',\n",
    "                 'RECFACPTH':'Recreation_facility',\n",
    "                 'PCT_NHWHITE':'White',\n",
    "                  'PCT_NHBLACK':'Black',\n",
    "                  'PCT_HISP':'Hispanic',\n",
    "                   'PCT_NHASIAN1':'Asian',\n",
    "                   'PCT_NHNA':'American Indian or Alaska Native',\n",
    "                    'PCT_NHPI':'Hawaiian or Pacific Islander',\n",
    "                    'PCT_65OLDER':'>=65',\n",
    "                    'PCT_18YOUNGER':'<18',\n",
    "                    'POVRATE':'Poverty_rate',\n",
    "                    'PCT_DIABETES_ADULT':'Adult_db',\n",
    "                    'PCT_OBESE_ADULTS':'Adult_ob'}\n",
    "\n",
    "cols=list(df_tp_1.columns)\n",
    "new_cols=list()\n",
    "for c in cols:\n",
    "    if c in ['State', 'County']:\n",
    "        new_cols.append(c)\n",
    "    else:\n",
    "        for k in var_trans_dict.keys():\n",
    "            if k in c:\n",
    "                new_cols.append(var_trans_dict[k])\n",
    "print (new_cols)\n",
    "df_tp_1.columns=new_cols\n",
    "\n",
    "          \n",
    "cols=list(df_tp_2.columns)\n",
    "new_cols=list()\n",
    "for c in cols:\n",
    "    if c in ['State', 'County']:\n",
    "        new_cols.append(c)\n",
    "    else:\n",
    "        for k in var_trans_dict.keys():\n",
    "            if k in c:\n",
    "                new_cols.append(var_trans_dict[k])\n",
    "df_tp_2.columns=new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df_tp_1.head(5))\n",
    "print (df_tp_2.head(5))\n",
    "print (df_pr.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tp_1.to_csv('C:/Users/cathy/Capstone_Project_1/Datasets/Food_atlas/df_tp_1.csv')\n",
    "df_tp_2.to_csv('C:/Users/cathy/Capstone_Project_1/Datasets/Food_atlas/df_tp_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate CDC Datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working on this ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
